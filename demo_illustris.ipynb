{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for Spherinator Training using Illustris\n",
    "\n",
    "## Download data\n",
    "\n",
    "the API key can be obtained from the Illustris website: https://www.tng-project.org/data/access/\n",
    "\n",
    "To avoid hardcoding the API key in the script, you can also store it in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ILLUSTRIS_API_KEY = \"PUT HERE YOUR ILLUSTRIS API KEY\"\n",
    "\n",
    "with open(\".illustris_api_key.txt\", \"r\") as file:\n",
    "    ILLUSTRIS_API_KEY = file.read().rstrip()\n",
    "\n",
    "subhalo_ids = [454795,454898,454963,455058,455109,455198,455258,455335,455413,\n",
    "               455479,455551,455637,455730,455857,455957,456014,456114,456168,\n",
    "               456234,456283,456381,456456,456538,456584,456634,456725,456786,\n",
    "               456872,456921,457000,457086,457169,457227,457296,457361,457452,\n",
    "               457514,457604,457697,457781,457871,457931,457998,458028,458111,\n",
    "               458174,458231,458302,458378,458447,458509,458604,458658,458722,\n",
    "               458784,458864,458945,459020,459084,459169,459243,459270,459360,\n",
    "               459394,459517,459576,459665,459730,459786,459850,459906,459959,\n",
    "               460008,460076,460117,460193,460273,460351,460434,460526,460595,\n",
    "               460692,460746,460823,460888,460939,461038,461136,461202,461283,\n",
    "               461364,461450,461521,461609,461667,461709,461806,461864,461929,\n",
    "               462010,462077,462141,462189,462241,462323,462391,462481,462564,\n",
    "               462631,462690,462775,462832,462904,462986,463062,463139,463233,\n",
    "               463278,463340,463395,463453,463521,463597,463649,463750,463804,\n",
    "               463894,463958,464018,464110,464182,464247,464292,464331,464422,\n",
    "               464490,464539,464576,464669,464742,464788,464894,464936,465016,\n",
    "               465080,465136,465205,465284,465320,465361,465412,465495,465548,\n",
    "               465614,465693,465764,465842,465921,466003,466055,466133,466182,\n",
    "               466265,466332,466387,466436,466493,466599,466694,466746,466801,\n",
    "               466894,466958,467011,467052,467127,467212,467256,467308,467385,\n",
    "               467445,467519,467575,467628,467700,467740,467798,467871,467919,\n",
    "               467958,468006,468064,468110,468168,468251,468318,468382,468450,\n",
    "               468508,468590]\n",
    "\n",
    "for sid in subhalo_ids:\n",
    "    if os.path.exists(f\"./data/illustris/fits/TNG100/sdss/snapnum_099/data/broadband_{sid}.fits\"):\n",
    "        continue\n",
    "    !wget -nc -P ./data/illustris/fits/TNG100/sdss/snapnum_099/data --content-disposition --header=\"API-Key: {ILLUSTRIS_API_KEY}\" \"http://www.tng-project.org/api/TNG100-1/snapshots/99/subhalos/{sid}/skirt/broadband_sdss.fits\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pest import FitsConverter\n",
    "\n",
    "image_size = 128\n",
    "FitsConverter(image_size).convert_all(\n",
    "    \"data/illustris/fits/TNG100/sdss/snapnum_099/data\", \"data/illustris/parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize training data\n",
    "\n",
    "To get an impression of the data, we can visualize the first 50 images of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure plots are displayed inline in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "dataset = ds.dataset(\"data/illustris/parquet\", format=\"parquet\")\n",
    "print(\"Number of data points:\", dataset.count_rows())\n",
    "\n",
    "df = dataset.to_table().to_pandas()\n",
    "\n",
    "fig, axes = plt.subplots(5, 10, figsize=(15, 8))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    data = np.array(df[\"data\"][i]).reshape(3, image_size, image_size).transpose(1, 2, 0) * 255\n",
    "    image = Image.fromarray(data.astype(np.uint8), \"RGB\")\n",
    "    ax.imshow(image)\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spherinator.models as sm\n",
    "\n",
    "model = sm.VariationalAutoencoder(\n",
    "    encoder=sm.ConvolutionalEncoder2D(\n",
    "        input_dim=[3, image_size, image_size],\n",
    "        output_dim=128,\n",
    "        cnn_layers=[\n",
    "            sm.ConsecutiveConv2DLayer(\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=0,\n",
    "                num_layers=1,\n",
    "                base_channel_number=16,\n",
    "                norm=None,\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    decoder=sm.ConvolutionalDecoder2D(\n",
    "        input_dim=3,\n",
    "        output_dim=[3, image_size, image_size],\n",
    "        cnn_input_dim=[128, 36],\n",
    "        cnn_layers=[\n",
    "            sm.ConsecutiveConvTranspose2DLayer(\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=0,\n",
    "                out_channels_list=[1],\n",
    "                norm=None,\n",
    "                activation=None,\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    z_dim=3,\n",
    "    beta=1.0e-4,\n",
    "    encoder_out_dim=128,\n",
    ")\n",
    "# _ = model(model.example_input_array)\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> use every pytorch module\n",
    "-> explain the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spherinator.data as sd\n",
    "\n",
    "datamodule = sd.ParquetDataModule(\n",
    "    data_directory=\"data/illustris/parquet\",\n",
    "    data_column=\"data\",\n",
    "    normalize=\"minmax\",\n",
    "    batch_size=256,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "datamodule.setup(\"fit\")\n",
    "dataloader = datamodule.train_dataloader()\n",
    "print(dataloader.batch_size)\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"gpu\",\n",
    "    precision=\"16-mixed\",\n",
    ")\n",
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the trained model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "onnx = torch.onnx.export(\n",
    "    model.variational_encoder,\n",
    "    torch.randn(1, 1, 343, device=\"cpu\"),\n",
    "    dynamic_axes={\"input\": {0: \"batch\"}},\n",
    "    dynamo=True,\n",
    ")\n",
    "onnx.optimize()\n",
    "onnx.save(\"data/illustris/models/encoder.onnx\")\n",
    "\n",
    "onnx = torch.onnx.export(\n",
    "    model.decoder,\n",
    "    torch.randn(1, 3, device=\"cpu\"),\n",
    "    dynamic_axes={\"input\": {0: \"batch\"}},\n",
    "    dynamo=True,\n",
    ")\n",
    "onnx.optimize()\n",
    "onnx.save(\"data/illustris/models/decoder.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the ONNX model with netron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q netron\n",
    "import netron\n",
    "netron.start('data/illustris/models/decoder.onnx', 8081)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Lightning Commnd Line Interface (CLI)\n",
    "\n",
    "Start the training using a unique [yaml config-file](./configs/spherinator/illustris.yaml) in reproducible mode.\n",
    "\n",
    "```bash\n",
    "spherinator fit --c configs/spherinator/illustris.yaml\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
